{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.io.wavfile import write\n",
    "from random import randint\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./datasets/16000_pcm_speeches/\"\n",
    "\n",
    "os.listdir(data_dir)\n",
    "\n",
    "def get_wav_paths(speaker):\n",
    "    speaker_path = data_dir + speaker\n",
    "    all_paths = [item for item in os.listdir(speaker_path)]\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nelson_mandela_paths = get_wav_paths(\"Nelson_Mandela\")\n",
    "margaret_thatcher_paths = get_wav_paths(\"Magaret_Tarcher\")\n",
    "benjamin_netanyau_paths = get_wav_paths(\"Benjamin_Netanyau\")\n",
    "jens_stoltenberg_paths = get_wav_paths( 'Jens_Stoltenberg')\n",
    "julia_gillard_paths = get_wav_paths(\"Julia_Gillard\")\n",
    "\n",
    "noise1_paths = get_wav_paths(\"_background_noise_\")\n",
    "noise2_paths = get_wav_paths(\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:02<00:00, 514.93it/s]\n",
      "100%|██████████| 1500/1500 [00:03<00:00, 474.62it/s]\n",
      "100%|██████████| 1500/1500 [00:03<00:00, 483.13it/s]\n",
      "100%|██████████| 1500/1500 [00:03<00:00, 495.31it/s]\n",
      "100%|██████████| 1501/1501 [00:02<00:00, 502.05it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_wav(wav_path, speaker):\n",
    "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
    "        wav_path = data_dir + speaker + \"/\" + wav_path\n",
    "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
    "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        wav_data = sess.run(\n",
    "            wav_decoder, feed_dict={\n",
    "                wav_filename_placeholder: wav_path\n",
    "            }).audio.flatten().reshape((1, 16000))\n",
    "        sess.close()\n",
    "    return wav_data\n",
    "\n",
    "def generate_training_data(speaker_paths, speaker, label):\n",
    "    wavs, labels = [], []\n",
    "    for i in tqdm(speaker_paths):\n",
    "        wav = load_wav(i, speaker)\n",
    "        wavs.append(wav)\n",
    "        labels.append(label)\n",
    "    return wavs, labels\n",
    "\n",
    "nelson_mandela_wavs, nelson_mandela_labels = generate_training_data(nelson_mandela_paths, \"Nelson_Mandela\", 0) \n",
    "margaret_thatcher_wavs, margaret_thatcher_labels = generate_training_data(margaret_thatcher_paths, \"Magaret_Tarcher\", 1) \n",
    "benjamin_netanyau_wavs, benjamin_netanyau_labels = generate_training_data(benjamin_netanyau_paths, \"Benjamin_Netanyau\", 2) \n",
    "jens_stoltenberg_wavs, jens_stoltenberg_labels = generate_training_data(jens_stoltenberg_paths, \"Jens_Stoltenberg\", 3) \n",
    "julia_gillard_wavs, julia_gillard_labels = generate_training_data(julia_gillard_paths, \"Julia_Gillard\", 4) \n",
    "\n",
    "# remove the extra wav for Julia Gillard\n",
    "julia_gillard_labels = julia_gillard_labels[1:]\n",
    "julia_gillard_wavs = julia_gillard_wavs[1:]\n",
    "\n",
    "all_wavs = nelson_mandela_wavs + margaret_thatcher_wavs + benjamin_netanyau_wavs + jens_stoltenberg_wavs + julia_gillard_wavs\n",
    "all_labels = nelson_mandela_labels + margaret_thatcher_labels + benjamin_netanyau_labels + jens_stoltenberg_labels + julia_gillard_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-fcc3b059c551>:42: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  fs, noise_file = read(data_dir + '_background_noise_/' + noise)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n"
     ]
    }
   ],
   "source": [
    "def cut_random_section(noise2, size2):\n",
    "    size21 = noise2.size\n",
    "    starting_point2 = randint(0,(noise2.size - size2))\n",
    "    end_point2 = starting_point2 + size2\n",
    "    noise_cut_part2 = noise2[starting_point2:end_point2]\n",
    "    return noise_cut_part2\n",
    "\n",
    "def mix(audio1, noise1, snr1):\n",
    "    audio_max = max(audio1)\n",
    "    if audio_max==0:\n",
    "        audio_max = int(np.random.uniform(0.7,1)*32767)\n",
    "    audio1 = audio1*1.\n",
    "    audio1 = audio1/audio_max\n",
    "    noise1 = cut_random_section(noise1, audio1.size)\n",
    "    noise1 = noise1*1.\n",
    "    noise1 = noise1/max(noise1)\n",
    "    gain = pow(10,(snr1/10.))\n",
    "    numerator = np.mean(abs(audio1)**2)\n",
    "    denominator = numerator/gain\n",
    "    noise_power = np.mean(abs(noise1)**2)\n",
    "    mult_value = (denominator/noise_power)**0.5\n",
    "    noisy1 = audio1 + noise1*mult_value\n",
    "    if max(audio1)==0:\n",
    "        noisy1 = noise1\n",
    "    else:    \n",
    "        noisy1 = noisy1/max(noisy1)\n",
    "    noisy1 = np.array(noisy1*audio_max, dtype='int16')\n",
    "    return noise1*mult_value, mult_value, noisy1\n",
    "\n",
    "noise_wavs = []\n",
    "noise_labels = []\n",
    "snr_dB = 10\n",
    "for i in range(len(all_wavs)):\n",
    "    for noise in os.listdir(data_dir + 'other'):\n",
    "        fs, noise_file = read(data_dir + 'other/' + noise)\n",
    "        x = all_wavs[i][0]\n",
    "        noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n",
    "        if noisy.any() != 0:\n",
    "            noise_wavs.append(noisy)\n",
    "            noise_labels.append(all_labels[i])\n",
    "    for noise in os.listdir(data_dir + '_background_noise_'):\n",
    "        fs, noise_file = read(data_dir + '_background_noise_/' + noise)\n",
    "        x = all_wavs[i][0]\n",
    "        if len(noise_file.shape) > 1:\n",
    "            noise_file = np.reshape(noise_file, (noise_file.shape[0]*noise_file.shape[1]))\n",
    "        noise_temp, mult_value, noisy = mix(x, noise_file, snr_dB)\n",
    "        if noisy.any() != 0:\n",
    "            noise_wavs.append(noisy)\n",
    "            noise_labels.append(all_labels[i]) \n",
    "    if i%200 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8155, 16000) (8155,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/librosa/filters.py:238: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 500\n",
      "Train 1000\n",
      "Train 1500\n",
      "Train 2000\n",
      "Train 2500\n",
      "Train 3000\n",
      "Train 3500\n",
      "Train 4000\n",
      "Train 4500\n",
      "Train 5000\n",
      "Train 5500\n",
      "Train 6000\n",
      "Train 6500\n",
      "Train 7000\n",
      "Test 500\n",
      "(7339, 126, 40, 1) (816, 126, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_wavs)):\n",
    "    noise_labels.append(all_labels[i])\n",
    "    noise_wavs.append(all_wavs[i][0])\n",
    "final_wavs = np.array(noise_wavs)\n",
    "final_labels = np.array(noise_labels)\n",
    "\n",
    "print(final_wavs.shape, final_labels.shape)\n",
    "\n",
    "# split the dataset into trainin and testing set\\\n",
    "train_wavs, test_wavs, train_labels, test_labels = train_test_split(final_wavs, final_labels, test_size=0.1)\n",
    "\n",
    "train_x, train_y = np.array(train_wavs), np.array(train_labels)\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)\n",
    "\n",
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)\n",
    "\n",
    "train_x_new = []\n",
    "test_x_new = []\n",
    "INPUT_SHAPE = (126,40)\n",
    "\n",
    "train_x_new = np.zeros((train_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
    "\n",
    "count = 0\n",
    "for sample in train_x:\n",
    "    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n",
    "    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n",
    "    train_x_new[count, :, :20] = mfcc.T\n",
    "    train_x_new[count, :, 20:30] = mfcc_delta.T\n",
    "    train_x_new[count, :, 30:] = mfcc_double_delta.T\n",
    "    count += 1\n",
    "    if count%500 == 0:\n",
    "        print('Train', count)\n",
    "        \n",
    "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
    "\n",
    "count = 0\n",
    "for sample in test_x:\n",
    "    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n",
    "    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n",
    "    test_x_new[count, :, :20] = mfcc.T\n",
    "    test_x_new[count, :, 20:30] = mfcc_delta.T\n",
    "    test_x_new[count, :, 30:] = mfcc_double_delta.T\n",
    "    count += 1\n",
    "    if count%500 == 0:\n",
    "        print('Test', count)\n",
    "        \n",
    "train_x_new = np.expand_dims(train_x_new, axis=3)\n",
    "test_x_new = np.expand_dims(test_x_new, axis=3)\n",
    "print(train_x_new.shape, test_x_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
